{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.95865931604268\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "def generator(lambda_):\n",
    "    return lambda_ * (np.random.exponential(size=len(lambda_)))\n",
    "\n",
    "lam = []\n",
    "for i in range(1,10000):\n",
    "    if i % 2 == 1:\n",
    "        lam.append(100)\n",
    "    else:\n",
    "        lam.append(1/100)\n",
    "\n",
    "seq=generator(lam)\n",
    "# seq.sort()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(seq)\n",
    "plt.show()\n",
    "print(statistics.mean(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " 100,\n",
       " 0.01,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--num-steps NUM_STEPS]\n",
      "                             [--hidden-size HIDDEN_SIZE]\n",
      "                             [--batch-size BATCH_SIZE] [--minibatch]\n",
      "                             [--log-every LOG_EVERY] [--anim-path ANIM_PATH]\n",
      "                             [--anim-every ANIM_EVERY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/peng/Library/Jupyter/runtime/kernel-9f760c1b-67c2-447d-8239-4fc4cf4c99e1.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "seq = []\n",
    "for i in range(1,10000):\n",
    "    if i % 2 == 1:\n",
    "        seq.append(100 * np.random.exponential(scale = i))\n",
    "    else:\n",
    "        seq.append(1/100 * np.random.exponential(scale = i))\n",
    "\n",
    "plt.plot(seq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07651146735358055"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.exponential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.zeros(shape=(5000,1000))\n",
    "for j in range(0,5000):\n",
    "    for i in range(0,1000):\n",
    "        if i % 2 == 1:\n",
    "            dataset[j][i] = 100 * np.random.exponential()\n",
    "        else:\n",
    "            dataset[j][i] = 1/100 * np.random.exponential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10, 39/39, d=1.169, g=0.221\n",
      ">Accuracy real: 93%, fake: 0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-1c138ec8e2d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-1c138ec8e2d8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0my_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# update the generator via the discriminator's error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;31m# summarize loss on this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3625\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3627\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# example of training a gan on mnist\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "def define_generator(z):\n",
    "    \"\"\"Generates a batch of images from random noise vectors z.\n",
    "    \n",
    "    Input: A batch of noise samples, arranged in a matrix of dimension BATCH_SIZE x NOISE_DIM\n",
    "    Output: A batch of generated images, arranged in a matrix of dimension BATCH_SIZE x IMAGE_SIZE\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_dim=z))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(700))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1000))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    return model\n",
    "\n",
    "def define_discriminator(x = (1000)):\n",
    "    \"\"\"Takes a batch of images x and returns a batch of scores that indicate how confident the discriminator\n",
    "    is that the each image is real.\n",
    "    \n",
    "    Input: A batch of images x, in a matrix of dimension BATCH_SIZE x IMAGE_SIZE\n",
    "    Output: A batch of real/fake scores, in a matrix of dimension BATCH_SIZE x 1\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(70, input_dim=x))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(30))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(g_model)\n",
    "    # add the discriminator\n",
    "    model.add(d_model)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = g_model.predict(x_input)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    # prepare real samples\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # create training set for the discriminator\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            # update discriminator model weights\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            # summarize loss on this batch\n",
    "\n",
    "        # evaluate the model performance, sometimes\n",
    "        if (i+1) % 10 == 0:\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "            \n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "d_model = define_discriminator()\n",
    "# create the generator\n",
    "g_model = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
