{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10, 390/390, d=0.365, g=1.481\n",
      ">Accuracy real: 93%, fake: 100%\n",
      ">20, 390/390, d=0.794, g=0.737\n",
      ">Accuracy real: 79%, fake: 41%\n",
      ">30, 390/390, d=0.771, g=0.693\n",
      ">Accuracy real: 85%, fake: 38%\n",
      ">40, 390/390, d=0.761, g=0.557\n",
      ">Accuracy real: 84%, fake: 29%\n",
      ">50, 390/390, d=0.629, g=1.206\n",
      ">Accuracy real: 53%, fake: 95%\n",
      ">60, 390/390, d=0.819, g=0.448\n",
      ">Accuracy real: 87%, fake: 10%\n",
      ">70, 390/390, d=0.772, g=1.477\n",
      ">Accuracy real: 3%, fake: 99%\n",
      ">80, 390/390, d=0.632, g=0.601\n",
      ">Accuracy real: 85%, fake: 33%\n",
      ">90, 390/390, d=0.670, g=1.387\n",
      ">Accuracy real: 27%, fake: 93%\n",
      ">100, 390/390, d=0.750, g=1.337\n",
      ">Accuracy real: 41%, fake: 88%\n",
      ">110, 390/390, d=0.586, g=1.419\n",
      ">Accuracy real: 35%, fake: 93%\n",
      ">120, 390/390, d=0.621, g=1.848\n",
      ">Accuracy real: 28%, fake: 97%\n",
      ">130, 390/390, d=0.571, g=1.052\n",
      ">Accuracy real: 75%, fake: 87%\n",
      ">140, 390/390, d=0.517, g=0.950\n",
      ">Accuracy real: 88%, fake: 58%\n",
      ">150, 390/390, d=0.543, g=0.931\n",
      ">Accuracy real: 67%, fake: 57%\n",
      ">160, 390/390, d=0.839, g=0.653\n",
      ">Accuracy real: 96%, fake: 37%\n",
      ">170, 390/390, d=0.480, g=1.773\n",
      ">Accuracy real: 33%, fake: 84%\n",
      ">180, 390/390, d=0.565, g=1.131\n",
      ">Accuracy real: 65%, fake: 70%\n",
      ">190, 390/390, d=0.617, g=0.667\n",
      ">Accuracy real: 90%, fake: 27%\n",
      ">200, 390/390, d=0.606, g=1.138\n",
      ">Accuracy real: 75%, fake: 85%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/device:GPU:2'):\n",
    "    import numpy as np\n",
    "\n",
    "    dataset = np.zeros(shape=(50000,1000))\n",
    "    for j in range(0,50000):\n",
    "        for i in range(0,1000):\n",
    "            if i % 2 == 1:\n",
    "                dataset[j][i] = 100 * np.random.exponential()\n",
    "            else:\n",
    "                dataset[j][i] = 1/100 * np.random.exponential()\n",
    "\n",
    "    from numpy import expand_dims\n",
    "    from numpy import zeros\n",
    "    from numpy import ones\n",
    "    from numpy import vstack\n",
    "    from numpy.random import randn\n",
    "    from numpy.random import randint\n",
    "    from keras.datasets.mnist import load_data\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Reshape\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers import Conv2D\n",
    "    from keras.layers import Conv2DTranspose\n",
    "    from keras.layers import LeakyReLU\n",
    "    from keras.layers import Dropout\n",
    "    from matplotlib import pyplot\n",
    "    def define_generator(z):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(300, input_dim=z))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(700))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1000))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        return model\n",
    "\n",
    "    def define_discriminator(x = (1000)):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(70, input_dim=x))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(30))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(10))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # compile model\n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def define_gan(g_model, d_model):\n",
    "        # make weights in the discriminator not trainable\n",
    "        d_model.trainable = False\n",
    "        # connect them\n",
    "        model = Sequential()\n",
    "        # add generator\n",
    "        model.add(g_model)\n",
    "        # add the discriminator\n",
    "        model.add(d_model)\n",
    "        # compile model\n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "        return model\n",
    "\n",
    "    def generate_real_samples(dataset, n_samples):\n",
    "        # choose random instances\n",
    "        ix = randint(0, dataset.shape[0], n_samples)\n",
    "        # retrieve selected images\n",
    "        X = dataset[ix]\n",
    "        # generate 'real' class labels (1)\n",
    "        y = ones((n_samples, 1))\n",
    "        return X, y\n",
    "\n",
    "    def generate_latent_points(latent_dim, n_samples):\n",
    "        # generate points in the latent space\n",
    "        x_input = randn(latent_dim * n_samples)\n",
    "        # reshape into a batch of inputs for the network\n",
    "        x_input = x_input.reshape(n_samples, latent_dim)\n",
    "        return x_input\n",
    "\n",
    "    def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "        # generate points in latent space\n",
    "        x_input = generate_latent_points(latent_dim, n_samples)\n",
    "        # predict outputs\n",
    "        X = g_model.predict(x_input)\n",
    "        # create 'fake' class labels (0)\n",
    "        y = zeros((n_samples, 1))\n",
    "        return X, y\n",
    "\n",
    "    def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "        # prepare real samples\n",
    "        X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "        # evaluate discriminator on real examples\n",
    "        _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "        # prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "        # evaluate discriminator on fake examples\n",
    "        _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "        # summarize discriminator performance\n",
    "        print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "\n",
    "    def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n",
    "        bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "        half_batch = int(n_batch / 2)\n",
    "        # manually enumerate epochs\n",
    "        for i in range(n_epochs):\n",
    "            # enumerate batches over the training set\n",
    "            for j in range(bat_per_epo):\n",
    "                # get randomly selected 'real' samples\n",
    "                X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "                # generate 'fake' examples\n",
    "                X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "                # create training set for the discriminator\n",
    "                X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "                # update discriminator model weights\n",
    "                d_loss, _ = d_model.train_on_batch(X, y)\n",
    "                # prepare points in latent space as input for the generator\n",
    "                X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "                # create inverted labels for the fake samples\n",
    "                y_gan = ones((n_batch, 1))\n",
    "                # update the generator via the discriminator's error\n",
    "                g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "                # summarize loss on this batch\n",
    "\n",
    "            # evaluate the model performance, sometimes\n",
    "            if (i+1) % 10 == 0:\n",
    "                print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "                summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "\n",
    "    # size of the latent space\n",
    "    latent_dim = 100\n",
    "    # create the discriminator\n",
    "    d_model = define_discriminator()\n",
    "    # create the generator\n",
    "    g_model = define_generator(latent_dim)\n",
    "    # create the gan\n",
    "    gan_model = define_gan(g_model, d_model)\n",
    "    # train model\n",
    "    train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "latent_points = generate_latent_points(100, 25)\n",
    "# generate images\n",
    "X = g_model.predict(latent_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
